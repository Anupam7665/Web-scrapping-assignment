{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fe1842a-0f00-4422-bf8e-97b59ca3b66c",
   "metadata": {},
   "source": [
    "### Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1eb3ac0-d228-45d5-a4db-03e81878d67f",
   "metadata": {},
   "source": [
    "Web scrapping means extraction of the data from websites.It  retrieve unstructured data from a website and store them in a structured format.This data is usually saved in the local file so that it can be manipualted and analyze as needed\n",
    "\n",
    "It is used to collect data from multiple websites for market research and compititor analysis.\n",
    "\n",
    "Monitoring price changes on e-ommerce websites\n",
    "\n",
    "Collect corporate contact information , including email address and phone number to sell their own  product by contacting them or mailing them.\n",
    "\n",
    "Area where web scrapping is used :\n",
    "\n",
    "**E-commerce** : Web scrapping is used to collet product information and prices from differnt e-commerce websites like amazon , flipkart etc\n",
    "\n",
    "**Research and analysis** : Web scrapping is used to collect data from different source to perform research and analysis in various field.\n",
    "\n",
    "**Marketing and sales** : Web scrapping is used to collect data on consumer behaviour and prefernce , competitor analysis , and social media monitoring to improve customer experience with the product\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac414f8-d156-4412-8b81-e543982e5068",
   "metadata": {},
   "source": [
    "### Q2. What are the different methods used for Web Scraping?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccb30ec-e805-43f9-837f-36a0898a11bb",
   "metadata": {},
   "source": [
    "**Manual Copy-Paste** : The simplest method is to copying and pasting data from a web pages into a local document or spreadsheet.\n",
    "\n",
    "**Web scrapping API** : This is a  method that uses an online services or a cloud based platform to perform web scrapping task.\n",
    "\n",
    "**Web scrapping services** : There are third party web scrapping services and tools that offer web scrapping services . User can configure  these services to scrape the data from specific websites \n",
    "\n",
    "\n",
    "Used customized _Python Script_ you can scrape the websites web pages data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b22a188-ae6c-40e3-847a-46e249fd4c39",
   "metadata": {},
   "source": [
    "### Q3. What is Beautiful Soup? Why is it used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08606927-6501-4f6c-89ce-8cfd6db0c95a",
   "metadata": {},
   "source": [
    "Beautiful soup is python library that makes it easy to scrape information from web pages . Beautiful soup is a class in _bs4_ module in python which is used to parse through html script and get data out of it.\n",
    "\n",
    "Beautiful  soup can help fix bad html and present it in easily XML structure.\n",
    "It also remove unwanted tags , attributes , comments etc from the html code. \n",
    "\n",
    "Beautiful soup is a popular and powerful tool for web scrapping in python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524e8e38-f588-4a95-8da9-a29c517c97fe",
   "metadata": {},
   "source": [
    "### Q4. Why is flask used in this Web Scraping project?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b904df-cbe9-43d5-bea4-c64b9f1c6ce4",
   "metadata": {},
   "source": [
    "Flask is a micro web framework in python that is commonly used for building web application , including web scrapping application .\n",
    "\n",
    "Flask can be used to create a web application that can scrape the data from websites , process the data and display it to the user as well as to handle the request and responses from the target websites\n",
    "\n",
    "Flask also supports various extension and libraries that can enhance its functionality.It is easy to setup and use , with minimal configuration and dependencies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e94fcef-fb21-4ad8-bcec-f7167191f25d",
   "metadata": {},
   "source": [
    "### Write the names of AWS services used in this project. Also, explain the use of each service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be41124a-b926-4ab9-860a-d89aa42c6b2c",
   "metadata": {},
   "source": [
    "Services used  in the project are :\n",
    "\n",
    "1 . **Beanstalk** : AWS Elastic Beanstalk is a fully managed service that makes it easy to deploy and scale web application and services . It provides an environment for hosting your web application that automatically handle the deployment \n",
    "\n",
    "\n",
    "2 . **Codepipelines** : AWS Codepipelines is a continous integration and continous (**CI/CD**) services used to bulit , test and deploy code . Codepipelines integrate with other AWS services like ElasticBeanstalk, Codecommit , CodeBilud , CodeDeploy allowing the user to build a complete CI/CD pipelines.Continuous delivery or deployment is the process of automatically releasing the software to different environments, such as testing, staging, or production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0a1aa8-26b5-4db9-b743-f6828f9e183c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
